{"cells":[{"cell_type":"code","execution_count":null,"id":"59089cca-71dd-4440-ae5e-0c6b3e039bf2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"59089cca-71dd-4440-ae5e-0c6b3e039bf2","executionInfo":{"status":"ok","timestamp":1725843183298,"user_tz":240,"elapsed":6376,"user":{"displayName":"Adrien Lacroix","userId":"08986805416727083279"}},"outputId":"e76a29cd-710b-479a-96fc-ee395d661522"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.2.90-py3-none-any.whl.metadata (41 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.4.0+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.19.0+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.4)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.6-py3-none-any.whl.metadata (9.1 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n","Downloading ultralytics-8.2.90-py3-none-any.whl (871 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m871.8/871.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.6-py3-none-any.whl (26 kB)\n","Installing collected packages: ultralytics-thop, ultralytics\n","Successfully installed ultralytics-8.2.90 ultralytics-thop-2.0.6\n"]}],"source":["!pip install ultralytics"]},{"cell_type":"code","execution_count":1,"id":"c9702934-44f5-447a-88bb-0d6a3303f312","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c9702934-44f5-447a-88bb-0d6a3303f312","executionInfo":{"status":"ok","timestamp":1727140427243,"user_tz":240,"elapsed":10166,"user":{"displayName":"Adrien Lacroix","userId":"08986805416727083279"}},"outputId":"f7eba583-b614-4890-b72a-1135be39e784"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting xlsxwriter\n","  Downloading XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\n","Downloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/159.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m153.6/159.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xlsxwriter\n","Successfully installed xlsxwriter-3.2.0\n","Collecting OneEuroFilter\n","  Downloading OneEuroFilter-0.2.1-py3-none-any.whl.metadata (3.9 kB)\n","Downloading OneEuroFilter-0.2.1-py3-none-any.whl (6.1 kB)\n","Installing collected packages: OneEuroFilter\n","Successfully installed OneEuroFilter-0.2.1\n"]}],"source":["!pip install xlsxwriter\n","!pip install OneEuroFilter --upgrade"]},{"cell_type":"markdown","id":"c27499f7-38a5-44db-87c5-8c7457c8d66a","metadata":{"id":"c27499f7-38a5-44db-87c5-8c7457c8d66a"},"source":["Functions that run the model on all videos in a folder, and create one CSV per video containing the model's predictions"]},{"cell_type":"code","execution_count":null,"id":"d7f37a6d-c8ea-4636-8cc8-21f36beded98","metadata":{"id":"d7f37a6d-c8ea-4636-8cc8-21f36beded98"},"outputs":[],"source":["import os\n","\n","from ultralytics import YOLO\n","import cv2\n","import csv\n","import numpy as np\n","\n","def list_avi_files(folder_path):\n","    \"\"\"\n","    Lists all .avi files in the given folder.\n","\n","    :param folder_path: Path to the folder\n","    :return: List of .mp4 file names\n","    \"\"\"\n","    try:\n","        # List all files in the folder\n","        files = os.listdir(folder_path)\n","        # Filter out only .avi files\n","        avi_files = [file for file in files if file.endswith('.avi')]\n","        return avi_files\n","    except Exception as e:\n","        return str(e)\n","\n","def predict_video_to_csv(directory: str, video_name: str, training_run: int, use_last: bool):\n","    '''\n","    Takes one video_name (str), one training_run (int) and use_last (bool) as inputs. Uses video_dir to locate a video to use, and then runs the model (specified by the training run number and use_last) on this video.\n","    '''\n","\n","    video_path = os.path.join(directory, video_name)\n","    video_basename = video_name.split(\".av\")[0]\n","\n","    cap = cv2.VideoCapture(video_path)\n","    ret, frame = cap.read()\n","    H, W, _ = frame.shape\n","\n","    # Determine which version of train{training_run} to use.\n","    best_or_last = 'best'\n","    if use_last:\n","        best_or_last = 'last'\n","\n","    model_path = os.path.join('.', 'runs', 'detect', f'train{str(training_run)}', 'weights', f'{best_or_last}.pt') #dot indicates PWD\n","    abs_model_path = 'drive/MyDrive/Colab Notebooks/' + model_path\n","    print(abs_model_path)\n","\n","    # Load a model\n","    model = YOLO(abs_model_path)  # load a custom model\n","\n","    threshold = 0.2\n","\n","    results_data = []\n","    results_frame_number = 1\n","    while ret:\n","\n","        results = model(frame)[0]\n","\n","        if len(results.boxes.data.tolist()) == 0:\n","            results_data.append([str(results_frame_number), '1', np.nan, np.nan, '0'])\n","\n","        obj_number = 1\n","        for result in results.boxes.data.tolist():\n","            x1, y1, x2, y2, score, class_id = result\n","            x = (x1 + x2)/2.0\n","            y = (y1 + y2)/2.0\n","            if score > threshold:\n","              results_data.append([results_frame_number, obj_number, x, y, score])\n","            else:\n","              results_data.append([results_frame_number, '1', np.nan, np.nan, '0'])\n","            obj_number += 1\n","\n","        ret, frame = cap.read()\n","        results_frame_number += 1\n","\n","    os.makedirs(f'{directory}/predicted_csvs/', exist_ok=True)\n","    csv_filename = f'{video_basename}.csv'\n","    csv_path = os.path.join(f'{directory}/predicted_csvs/', csv_filename)\n","\n","    # Create the CSV file\n","    with open(csv_path, 'w', newline='') as csvfile:\n","        csvwriter = csv.writer(csvfile)\n","        csvwriter.writerow(['Frame Number', 'Object Number', 'X', 'Y', 'Confidence Score'])\n","\n","        for row in results_data:\n","            csvwriter.writerow(row)\n","\n","    cap.release()\n","    cv2.destroyAllWindows()\n","\n","def predict_videos_to_csv(video_directory: str, training_run: int, use_last: bool):\n","    '''\n","    Searches through the video_directory and uses the model specified by training_run (int) and use_last (bool) to run the model on the videos.\n","\n","    When use_last is True, the model selected by the function will be the specified training run's 'last.pt'. rather than the 'best.pt'.\n","    '''\n","\n","    for file in list_avi_files(video_directory):\n","        predict_video_to_csv(video_directory, file, training_run, use_last)"]},{"cell_type":"markdown","id":"4a877287-c637-4df0-b51f-ac558df8e563","metadata":{"id":"4a877287-c637-4df0-b51f-ac558df8e563"},"source":["Use predict_videos_to_csv function to create CSVs containing the model's predictions"]},{"cell_type":"code","execution_count":null,"id":"c5855cc7-a4f1-4266-b3bd-52f46fa22947","metadata":{"scrolled":true,"id":"c5855cc7-a4f1-4266-b3bd-52f46fa22947"},"outputs":[],"source":["#predict_videos_to_csv(26, False)"]},{"cell_type":"markdown","id":"38fe4b1a-7a12-44d2-aea6-e1b0c7ddc1b6","metadata":{"id":"38fe4b1a-7a12-44d2-aea6-e1b0c7ddc1b6"},"source":["Functions to correct for missed frames in the model's predictions (this one is an old one, the next one is the correct one)"]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","\n","def correct_csv_files(directory, xy_cal):\n","    '''\n","    Corrects all mistakes in the csv files in {directory}; deletes all multiple detections in favour of the highest confidence detection, and fills in all missing detections by linear interpolation.\n","    '''\n","    corrected_dir = os.path.join(directory, \"corrected_csvs\")\n","    os.makedirs(corrected_dir, exist_ok=True)\n","\n","    def distance(x1, y1, x2, y2):\n","        return np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n","\n","    def correct_detections(df, xy_cal, max_velocity=300, max_distance=10, initial_position=(320, 240)):\n","        # Convert initial position from pixels to millimeters\n","        previous_x, previous_y = initial_position[0] * xy_cal, initial_position[1] * xy_cal\n","        corrected_rows = []\n","\n","        for frame in range(1, df['Frame Number'].max() + 1):\n","            frame_data = df[df['Frame Number'] == frame].copy()\n","\n","            if frame_data.empty:\n","                continue\n","\n","            best_row = None\n","            best_distance = float('inf')\n","\n","            for _, row in frame_data.iterrows():\n","                # Convert x and y from pixels to millimeters\n","                x, y, confidence = row['X'] * xy_cal, row['Y'] * xy_cal, row['Confidence Score']\n","                dist = distance(previous_x, previous_y, x, y)\n","\n","                if dist <= max_distance and dist < best_distance:\n","                    best_distance = dist\n","                    best_row = row\n","\n","            if best_row is None:\n","                frame_data['Distance'] = frame_data.apply(\n","                    lambda r: distance(previous_x, previous_y, r['X'] * xy_cal, r['Y'] * xy_cal), axis=1\n","                    )\n","                if frame_data['Distance'].notna().any():\n","                    best_row = frame_data.loc[frame_data['Distance'].idxmin()]\n","\n","            if best_row is not None:\n","                corrected_rows.append(best_row)\n","                previous_x, previous_y = best_row['X'] * xy_cal, best_row['Y'] * xy_cal\n","\n","        corrected_df = pd.DataFrame(corrected_rows)\n","\n","        if 'Distance' in corrected_df.columns:\n","          corrected_df.drop('Distance', axis=1, inplace=True)\n","\n","        return corrected_df\n","\n","    def remove_leading_trailing_nans(df):\n","        # Drop leading rows with NaN values in columns 3 and 4\n","        while pd.isna(df.iloc[0, 2]) or pd.isna(df.iloc[0, 3]):\n","            df = df.iloc[1:]\n","\n","        # Drop trailing rows with NaN values in columns 3 and 4\n","        while pd.isna(df.iloc[-1, 2]) or pd.isna(df.iloc[-1, 3]):\n","            df = df.iloc[:-1]\n","\n","        return df.reset_index(drop=True)\n","\n","    def sanity_check(df, xy_cal, max_distance=10, distance_increment=2):\n","        \"\"\"\n","        Processes the DataFrame by replacing x and y values with NaN if the distance\n","        from the previous row to the current row exceeds 10mm in real space or if the velocity exceeds 300mm/s.\n","\n","        Parameters:\n","            df (pd.DataFrame): DataFrame with at least 5 columns. x and y values are in columns 2 and 3 (0-indexed).\n","            xy_cal (float): Calibration factor to convert pixel values to real space.\n","\n","        Returns:\n","            pd.DataFrame: Modified DataFrame with updated x and y values.\n","        \"\"\"\n","        df = df.reset_index(drop=True)  # Reset the index to ensure continuous integer indexing\n","        for i in range(1, len(df)):\n","            if pd.isna(df.loc[i, 'X']) or pd.isna(df.loc[i, 'Y']):\n","                continue\n","\n","            previous_index = i - 1\n","            nan_count = 0\n","            while previous_index >= 0 and (pd.isna(df.loc[previous_index, 'X']) or pd.isna(df.loc[previous_index, 'Y'])):\n","                previous_index -= 1\n","                nan_count += 1\n","\n","            if previous_index < 0:\n","                continue\n","\n","            x1, y1 = df.loc[previous_index, ['X', 'Y']] * xy_cal\n","            x2, y2 = df.loc[i, ['X', 'Y']] * xy_cal\n","            max_distance_adjusted = max_distance + nan_count * distance_increment\n","            distance_traveled = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n","\n","            if distance_traveled > max_distance_adjusted:\n","                df.loc[i, ['X', 'Y']] = np.nan\n","\n","        return df\n","\n","    def interpolate_consecutive_nans(df):\n","        \"\"\"\n","        Interpolates NaN values using linear interpolation. If there are too many consecutive NaNs,\n","        uses the last valid value.\n","\n","        Parameters:\n","            df (pd.DataFrame): DataFrame with NaN values to interpolate.\n","\n","        Returns:\n","            pd.DataFrame: Modified DataFrame with interpolated values.\n","        \"\"\"\n","        max_consecutive_nans = 5  # Define a threshold for maximum consecutive NaNs\n","\n","        # Interpolate NaNs\n","        df.interpolate(axis=0, inplace=True)\n","\n","        # Handle consecutive NaNs by using the last valid value\n","        for col in [2, 3]:  # x and y columns\n","            is_nan = df.iloc[:, col].isna()\n","            for i in range(len(df)):\n","                if is_nan[i]:\n","                    start_idx = i\n","                    while i < len(df) and is_nan[i]:\n","                        i += 1\n","                    if (i - start_idx) > max_consecutive_nans:\n","                        df.iloc[start_idx:i, col] = df.iloc[start_idx - 1, col]\n","\n","        return df\n","\n","    for filename in os.listdir(directory):\n","        if filename.endswith('.csv'):\n","            filepath = os.path.join(directory, filename)\n","            df = pd.read_csv(filepath)\n","\n","            # remove leading and trailing failed detections\n","            df = remove_leading_trailing_nans(df)\n","\n","            # correct multiple detections\n","            df = correct_detections(df, xy_cal)\n","\n","            # correct erroneous detections by replacing the erroneous x and y values by np.nan\n","            df = sanity_check(df, xy_cal)\n","\n","            # correct failed detections values by linear interpolation\n","            df = interpolate_consecutive_nans(df)\n","\n","            # Return corrected df to a csv\n","            filepath_out = os.path.join(corrected_dir, filename)\n","            df.to_csv(filepath_out, index=False)\n"],"metadata":{"id":"nrwbhQPCxOYP","executionInfo":{"status":"ok","timestamp":1726445279763,"user_tz":240,"elapsed":191,"user":{"displayName":"Adrien Lacroix","userId":"08986805416727083279"}}},"id":"nrwbhQPCxOYP","execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"118d7ffd-cea9-4818-b4c2-02f59967b3ee","metadata":{"id":"118d7ffd-cea9-4818-b4c2-02f59967b3ee"},"outputs":[],"source":["#correct_csv_files(\"/home/jovyan/work/predicted_csvs/train26\")"]},{"cell_type":"code","execution_count":null,"id":"e9e29426-b25c-43cf-bb7f-85b7f3ad9659","metadata":{"id":"e9e29426-b25c-43cf-bb7f-85b7f3ad9659"},"outputs":[],"source":["#input_excel_file = '/home/jovyan/work/xlsx fish data/CRISPent inppf5 Touch Response 12-06-24.xlsx'\n","#output_csv_file = '/home/jovyan/work/xlsx fish data/first_swim_velocity.csv'\n","#find_first_velocity(input_excel_file, output_csv_file)"]},{"cell_type":"markdown","id":"84f03c62-af43-43f4-b8b4-4629532c3e35","metadata":{"id":"84f03c62-af43-43f4-b8b4-4629532c3e35"},"source":["Use the csv files containing the (corrected) model predictions, and then calculate the desired metrics (swim duration, distance, mean velocity, max velocity)"]},{"cell_type":"code","execution_count":26,"id":"61af3245-4bd2-4fe7-b23f-2a293e6fa602","metadata":{"id":"61af3245-4bd2-4fe7-b23f-2a293e6fa602","executionInfo":{"status":"ok","timestamp":1727142735894,"user_tz":240,"elapsed":244,"user":{"displayName":"Adrien Lacroix","userId":"08986805416727083279"}}},"outputs":[],"source":["import os\n","import re\n","import glob\n","import numpy as np\n","import pandas as pd\n","import openpyxl\n","from OneEuroFilter import OneEuroFilter\n","\n","def calculate_velocity(x, y, frame_rate=30):\n","    \"\"\"\n","    Calculates the velocity between each consecutive (x, y) point.\n","\n","    Args:\n","        x (list or np.array): X position data.\n","        y (list or np.array): Y position data.\n","        frame_rate (float): Frame rate of the data (frames per second).\n","\n","    Returns:\n","        velocity (np.array): Velocity at each frame, calculated as the distance between consecutive points.\n","    \"\"\"\n","    # Calculate the distances between consecutive points\n","    distances = np.sqrt(np.diff(x)**2 + np.diff(y)**2)\n","\n","    # Convert distances to velocities (velocity = distance / time)\n","    # Time between frames is 1 / frame_rate\n","    velocities = distances * frame_rate\n","\n","    return velocities\n","\n","def filter_position_data(x_data, y_data, frame_rate, fcmin=1, beta=0, dc=1):\n","    \"\"\"\n","    Filters x and y position data using the OneEuroFilter.\n","\n","    Args:\n","        x_data (list or np.array): The x position data.\n","        y_data (list or np.array): The y position data.\n","        freq (float): Frequency of the data in Hz (sampling rate). Default is 30 Hz.\n","        min_cutoff (float): Minimum cutoff frequency. Default is 1.0.\n","        beta (float): Speed coefficient. Adjusts the filter’s sensitivity to speed. Default is 0.0.\n","        d_cutoff (float): Cutoff frequency for the derivative of the signal. Default is 1.0.\n","\n","    Returns:\n","        filtered_x (np.array): Filtered x position data.\n","        filtered_y (np.array): Filtered y position data.\n","    \"\"\"\n","\n","    # Create OneEuroFilter\n","    config = {\n","      'freq': 30,       # Hz\n","      'mincutoff': fcmin,  # Hz\n","      'beta': beta,\n","      'dcutoff': dc\n","      }\n","\n","    f_x = OneEuroFilter(**config)\n","    f_y = OneEuroFilter(**config)\n","\n","    filtered_x = []\n","    filtered_y = []\n","\n","    # Apply the filter to the position data\n","    for t, (x, y) in enumerate(zip(x_data, y_data)):\n","        time = t / frame_rate  # Convert index to time based on the sampling rate\n","        filtered_x.append(f_x(x, time))\n","        filtered_y.append(f_y(y, time))\n","\n","    return np.array(filtered_x), np.array(filtered_y)\n","\n","def find_start_end_rows(df, x_pos, y_pos, frame_rate):\n","        \"\"\"\n","        Find the start and end row indices based on positional data filtering and subsequent analysis of velocity based on the filtered position data.\n","\n","        Parameters:\n","        df (pd.DataFrame): The dataframe to analyze.\n","        x_pos, y_pos (str): filtered x and y positional data.\n","\n","        Returns:\n","        tuple: A tuple containing the start row index and the end row index.\n","        \"\"\"\n","        filtered_x, filtered_y = filter_position_data(df.loc[:, x_pos].to_numpy(), df.loc[:, y_pos].to_numpy(), frame_rate, fcmin=0.1, beta=0.1, dc=1)\n","\n","        velocity_filtered_pos = calculate_velocity(filtered_x, filtered_y, frame_rate)\n","\n","        # Prepend a 0 for the first frame (no movement before the first frame)\n","        velocity_filtered_pos = np.insert(velocity_filtered_pos, 0, 0)\n","\n","        # Create columns of filtered data and velocity in the df\n","        df['X_real_filt'] = pd.Series(filtered_x)\n","        df['Y_real_filt'] = pd.Series(filtered_y)\n","        df['vel_from_filt'] = pd.Series(velocity_filtered_pos)\n","\n","        #print(df['vel_from_filt'].to_string(index=False))\n","\n","        start_row = None\n","        end_row = None\n","        filtered_velocity_threshold = 10\n","        end_filtered_velocity_threshold = 10 # Minimum filtered velocity to consider movement\n","        consistent_low_velocity_frames = 8  # Number of consecutive low-velocity frames to detect the end\n","\n","        # Find the start row\n","        for i in range(len(df)):\n","            if df.loc[i, 'vel_from_filt'] >= filtered_velocity_threshold:\n","                start_row = i - 1\n","                break\n","\n","        # If start_row is still None, it means no value >= 20 was found\n","        if start_row is None:\n","            return (-1,-1)  # -1 indicates the function failed\n","\n","        # Find end row by iterating in reverse order over the filtered velocity values\n","        for i in range(len(df) - 1, start_row + 1, -1):\n","            if velocity_filtered_pos[i] >= filtered_velocity_threshold:\n","                end_row = i\n","                break\n","\n","        # If end_row is still None, it means no consistent low-velocity frames were found\n","        if end_row is None:\n","            end_row = len(df) - 1\n","\n","        return start_row, end_row\n","\n","def extract_metrics_from_predictions(xy_cal, frame_rate, csv_path, vid_num):\n","    '''\n","    Defines the start and end of zebrafish movement within a video's csv based on a hard-coded threshold for minimum velocity. Uses the start frame and end frame to create a new csv containing only the frames of interest.\n","\n","    {xy_cal} must be obtained manually. It is obtained by using ImageJ's ruler tool to measure the number of pixels taken by the diameter of the petri dish within the video. By comparing the number of pixels to a known real world measurement (petri dish),\n","    we obtain the real world \"length\" occupied by a single pixel. The formula is:\n","\n","    xy calibration = [diameter of petri dish (in mm)] / [# of pixels]\n","\n","    A normal xy calibration value is approximately 0.35, but can vary to as low as 0.32 and as high as 0.37 depending on the camera's height above the petri dish (e.g., when the camera is closer, each pixel accounts for a smaller real life measure, therefore increasing the size of\n","    the equation's denominator (more pixels required to fill the same space) and increasing the xy calibration value. Essentially, a closer camera means larger value of xy.)\\\n","\n","    The units of xy_cal are mm/pixel.\n","\n","    {frame_rate} is a required input in order to calculate the velocity of the fish. By using the time between frames, and the position at frame A versus frame B, the function performs the operation: (pos_at_frame_B - pos_at_frame_A / time_btn_frames) to obtain the fish's velocity\n","    '''\n","    df = pd.read_csv(csv_path)\n","\n","    # Create output CSV path\n","    new_csv_path = os.path.split(csv_path)[0] + '/formatted_data/' + os.path.split(csv_path)[1]\n","    os.makedirs(os.path.split(new_csv_path)[0], exist_ok=True)\n","\n","    # define a helper function so that we can use the .apply() method on the xy columns\n","    def convert_to_real_space(cell):\n","        new_cell = cell * xy_cal\n","        return new_cell\n","\n","    def convert_to_pixel_space(cell):\n","        new_cell = cell / xy_cal\n","        return new_cell\n","\n","    # create real space X and Y values in two new columns\n","    df['X_real'] = df['X'].map(convert_to_real_space)\n","    df['Y_real'] = df['Y'].map(convert_to_real_space)\n","\n","    # Find the rows of interest, i.e. those in which the fish is moving\n","    start_row, end_row = find_start_end_rows(df, 'X_real', 'Y_real', frame_rate)\n","\n","    if start_row == -1:\n","      print(f\"No movement detected in video #{vid_num}!\")\n","      return\n","\n","    # create the distance column\n","    df['distance_since_last_frame'] = np.nan  # Initialize the new column with NaN\n","    df.loc[1:, 'distance_since_last_frame'] = np.sqrt((df.loc[1:, 'X_real_filt'] - df['X_real_filt'].shift(1).iloc[1:])**2 + (df.loc[1:, 'Y_real_filt'] - df['Y_real_filt'].shift(1).iloc[1:])**2)\n","\n","    # Create filtered X and Y that are in pixel space\n","    df['X_filt'] = df['X_real_filt'].map(convert_to_pixel_space)\n","    df['Y_filt'] = df['Y_real_filt'].map(convert_to_pixel_space)\n","\n","    # Create subset_df which contains only the frames during which the fish is moving\n","    subset_df = df.iloc[start_row:end_row + 1]\n","    subset_df = subset_df.copy()\n","\n","    # Debugging: Print the DataFrame and the start_row\n","    #print(\"df:\")\n","    #print(df)\n","    #print(\"subset_df:\")\n","    #print(subset_df)\n","    print(\"start_row:\", start_row)\n","    print(\"end_row:\", end_row)\n","\n","    # Create normalized X and Y rows (which are used to create figures by hand after data processing)\n","    subset_df.loc[:, 'X_norm'] = subset_df['X_real_filt'] - subset_df.loc[start_row, 'X_real_filt']\n","    subset_df.loc[:, 'Y_norm'] = subset_df['Y_real_filt'] - subset_df.loc[start_row, 'Y_real_filt']\n","\n","    # Calculate the values for the metric column\n","    swim_duration = (subset_df.loc[end_row, 'Frame Number'] - subset_df.loc[start_row, 'Frame Number']) * (1 / frame_rate)\n","    swim_distance = subset_df['distance_since_last_frame'].sum()\n","    mean_swim_velocity = subset_df['vel_from_filt'].mean()\n","    max_swim_velocity = subset_df['vel_from_filt'].max()\n","\n","    # Create the metrics dataframe\n","    metrics_list = [['swim duration', swim_duration], ['swim distance', swim_distance], ['mean swim velocity', mean_swim_velocity], ['max swim velocity', max_swim_velocity]]\n","    metrics_df = pd.DataFrame(metrics_list)\n","\n","    # Format the dataframe\n","    df_formatted = subset_df[['Frame Number', 'X_filt', 'Y_filt', 'X_norm', 'Y_norm', 'distance_since_last_frame', 'vel_from_filt']]\n","\n","    # Combine the dataframes manually because .concat refuses to work\n","    df_formatted = df_formatted.reset_index(drop=True)\n","    metrics_df = metrics_df.reset_index(drop=True)\n","\n","    # Determine the maximum number of rows needed\n","    max_len = max(len(df_formatted), len(metrics_df))\n","\n","    # Create an empty dataframe with the appropriate columns\n","    df_out = pd.DataFrame(index=range(max_len), columns=df_formatted.columns.tolist() + metrics_df.columns.tolist())\n","\n","    # Fill the new dataframe with values from df_formatted and metrics_df\n","    df_out[df_formatted.columns] = df_formatted\n","    df_out[metrics_df.columns] = metrics_df\n","\n","    df_out.to_csv(new_csv_path, index=False)\n","\n","    # Create a csv for testing purposes\n","    #test_csv_path = os.path.split(new_csv_path)[0] + '/test_4.csv'\n","    #df_out_2 = df[['Frame Number', 'X', 'Y', 'distance_since_last_frame', 'velocity_since_last_frame', 'filtered_velocity']]\n","    #df_out_2.to_csv(test_csv_path, index=False)\n","\n","def extract_metrics_from_directory(xy_cal, frame_rate, directory):\n","    '''\n","    Calls the extract_metrics_from_predictions function on all CSVs in a directory.\n","    '''\n","    csv_files = glob.glob(os.path.join(directory, '*.csv'))\n","\n","    vid_num=1\n","    for file in csv_files:\n","        print(f\"This is for csv #{vid_num}\")\n","        extract_metrics_from_predictions(xy_cal, frame_rate, file, vid_num)\n","        vid_num+=1\n","\n","def format_csv_for_imagej(df, directory, output_csv):\n","    '''\n","    Takes one formatted_data CSV file (as a pandas dataframe) as input, and arranges the columns using pandas such that the output CSV can be read into\n","    ImageJ's manual tracking plugin along with its associated annotated video file.\n","    '''\n","    # Initialize the output dataframe with the required columns\n","    output_df = pd.DataFrame()\n","\n","    # Fill the empty header column with sequential numbers starting from 1\n","    output_df[''] = range(1, len(df) + 1)\n","\n","    # Fill the 'Track n°' column with 1s\n","    output_df['Track n°'] = 1\n","\n","    # Copy the 'Slice n°' (Frame Number) from the input dataframe\n","    output_df['Slice n°'] = df['Frame Number']\n","\n","    # Copy the X and Y data from the input dataframe\n","    output_df['X'] = df['X_filt']\n","    output_df['Y'] = df['Y_filt']\n","\n","    # Set the 'Distance', 'Velocity', and 'Pixel Value' columns to 0\n","    output_df['Distance'] = 0\n","    output_df['Velocity'] = 0\n","    output_df['Pixel Value'] = 0\n","\n","    # Ensure the columns are in the correct order\n","    output_df = output_df[['', 'Track n°', 'Slice n°', 'X', 'Y', 'Distance', 'Velocity', 'Pixel Value']]\n","\n","    # Write the output dataframe to a CSV file\n","    output_dir = MASTER_VIDEO_DIRECTORY + '/predictions'\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    output_txt = output_csv.split('.csv')[0] + '.txt'\n","\n","    output_filepath = os.path.join(output_dir, output_txt)\n","    output_df.to_csv(output_filepath, sep='\\t', index=False)\n","\n","\n","def combine_csv_to_xlsx(directory):\n","    '''\n","    Combines all formatted data CSVs in one directory into one large xlsx file, which contains two sheets: one with all the data, and the other a summary page\n","    '''\n","    #Create the filepath for the output file\n","    output_file = os.path.split(MASTER_VIDEO_DIRECTORY)[-1] + '_results.xlsx'\n","    output_path = os.path.join(MASTER_VIDEO_DIRECTORY, output_file)\n","\n","    # Create a writer object to write to Excel file\n","    with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:\n","        # Initialize a variable to keep track of the current row in the 'Fish Data' sheet\n","        current_row = 0\n","\n","        # Create empty DataFrame for Data Overview\n","        data_overview = pd.DataFrame(columns=['Fish Number', 'Swim Duration', 'Swim Distance', 'Mean Swim Velocity', 'Max Swim Velocity'])\n","\n","        # Initialize lists to store data for calculations\n","        col9_1_list, col9_2_list, col9_3_list, col9_4_list = [], [], [], []\n","\n","        fish_number = 1\n","\n","        # Define and use a natural sort function to turn the filename list into human readable form (i.e. csvs listed in order)\n","        def natural_sort_key(s):\n","            return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n","\n","        filenames = [filename for filename in os.listdir(directory) if filename.endswith(\".csv\")]\n","        filenames.sort(key=natural_sort_key)\n","\n","        for filename in filenames:\n","            if filename.endswith(\".csv\"):\n","                # Read the CSV file\n","                csv_path = os.path.join(directory, filename)\n","                df = pd.read_csv(csv_path)\n","\n","                # Check if the CSV file has at least 9 columns\n","                if df.shape[1] < 9:\n","                    print(f\"Skipping {filename} as it has fewer than 9 columns\")\n","                    continue\n","\n","                # Create a CSV that can be opened in ImageJ, for review\n","                format_csv_for_imagej(df, MASTER_VIDEO_DIRECTORY, filename)\n","\n","                # Create a new DataFrame with the required structure\n","                fish_df = pd.DataFrame(columns=['Fish Number'] + df.columns.tolist() + ['Blank'])\n","                fish_df['Fish Number'] = ['Fish {}'.format(fish_number)] + [''] * (len(df) - 1)\n","                fish_df[df.columns] = df\n","                fish_df['Blank'] = ''\n","\n","                # Determine the starting column for the current fish data\n","                startcol = (fish_number - 1) * 11\n","\n","                # Append the fish_df to the Excel writer\n","                fish_df.to_excel(writer, sheet_name='Fish Data', startrow=0, startcol=startcol, index=False, header=True)\n","\n","                # Update the current row\n","                current_row += len(fish_df) + 1  # +1 for the header row\n","\n","                # Extract the required data for Data Overview\n","                col9_data = df.iloc[:, 8]\n","                col9_1_list.append(col9_data.iloc[0])\n","                col9_2_list.append(col9_data.iloc[1])\n","                col9_3_list.append(col9_data.iloc[2])\n","                col9_4_list.append(col9_data.iloc[3])\n","\n","                fish_number += 1\n","\n","        # Construct the Data Overview DataFrame\n","        data_overview['Fish Number'] = ['Fish {}'.format(i+1) for i in range(len(col9_1_list))]\n","        data_overview['Swim Duration'] = col9_1_list\n","        data_overview['Swim Distance'] = col9_2_list\n","        data_overview['Mean Swim Velocity'] = col9_3_list\n","        data_overview['Max Swim Velocity'] = col9_4_list\n","\n","        # Create the labels and values DataFrame\n","        labels_values = pd.DataFrame({\n","            'Label': ['average swim duration (s)', 'average swim distance (mm)', 'average mean swim velocity (mm/s)', 'average max swim velocity (mm/s)'],\n","            'Value': [data_overview['Swim Duration'].mean(), data_overview['Swim Distance'].mean(), data_overview['Mean Swim Velocity'].mean(), data_overview['Max Swim Velocity'].mean()]\n","        })\n","\n","        # Write the Data Overview and labels/values to the second sheet\n","        data_overview.to_excel(writer, sheet_name='Data Overview', index=False)\n","        labels_values.to_excel(writer, sheet_name='Data Overview', startrow=len(data_overview) + 2, index=False)\n"]},{"cell_type":"markdown","id":"ae86c3c2-fa91-412b-a160-3477a9e59ff1","metadata":{"id":"ae86c3c2-fa91-412b-a160-3477a9e59ff1"},"source":["Use the functions created in this project so far to create a master function that takes a directory full of videos as input, as well as an xy_calibration value, and frame_rate, and then outputs an xlsx file containing the processed data."]},{"cell_type":"code","execution_count":27,"id":"f0783c8a-7a01-4015-be57-837b7a8d6651","metadata":{"id":"f0783c8a-7a01-4015-be57-837b7a8d6651","executionInfo":{"status":"ok","timestamp":1727142744968,"user_tz":240,"elapsed":261,"user":{"displayName":"Adrien Lacroix","userId":"08986805416727083279"}}},"outputs":[],"source":["import shutil\n","\n","def videos_to_fish_data(video_directory, xy_cal, frame_rate):\n","    '''\n","    Calls helper functions to direct the extraction of predictions, then corrects predictions, then extracts data from predictions.\n","    '''\n","    #predict_videos_to_csv(video_directory, 30, False)\n","    #print(\"predict_videos_to_csv ran successfully\")\n","\n","    csv_directory = os.path.join(video_directory, 'predicted_csvs')\n","    #correct_csv_files(csv_directory, xy_cal)\n","    #print(\"correct_csv_files ran successfully\")\n","\n","    corrected_directory = os.path.join(csv_directory, 'corrected_csvs')\n","    #extract_metrics_from_directory(xy_cal, frame_rate, corrected_directory)\n","    #print(\"extract_metrics_from_directory ran successfully\")\n","\n","    formatted_csv_directory = os.path.join(corrected_directory, 'formatted_data')\n","    combine_csv_to_xlsx(formatted_csv_directory)\n","    print(\"combine_metrics ran successfully\")\n","\n","    # remove temporary files\n","    #shutil.rmtree(f'drive/MyDrive/Colab Notebooks/Zebrafish Data/{video_directory}/predicted_csvs')\n","    #print(\"removed temporary directory\")"]},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount(\"/content/drive\", force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UfZzkJqSCoSM","executionInfo":{"status":"ok","timestamp":1727142750373,"user_tz":240,"elapsed":2965,"user":{"displayName":"Adrien Lacroix","userId":"08986805416727083279"}},"outputId":"41ac55e7-7ae7-4270-a898-47c8a4e96711"},"id":"UfZzkJqSCoSM","execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!ls 'drive/MyDrive/Colab Notebooks/Zebrafish Data/TDP43 G348C Touch Response 02-08-24/WT/predicted_csvs/corrected_csvs/formatted_data'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"Ul7CtZOQ6iY-","executionInfo":{"status":"ok","timestamp":1727142752045,"user_tz":240,"elapsed":244,"user":{"displayName":"Adrien Lacroix","userId":"08986805416727083279"}},"outputId":"6f5b0bae-1e24-45f5-9978-48a5e614a86c"},"id":"Ul7CtZOQ6iY-","execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["ls: cannot access 'drive/MyDrive/Colab Notebooks/Zebrafish Data/TDP43 G348C Touch Response 02-08-24/WT/predicted_csvs/corrected_csvs/formatted_data': No such file or directory\n"]}]},{"cell_type":"code","execution_count":30,"id":"ee8807d0-cb70-4ba6-a877-079891d2b8b4","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"ee8807d0-cb70-4ba6-a877-079891d2b8b4","executionInfo":{"status":"ok","timestamp":1727142758332,"user_tz":240,"elapsed":3824,"user":{"displayName":"Adrien Lacroix","userId":"08986805416727083279"}},"outputId":"ef16c0f4-a532-406d-9360-296004bbeab7"},"outputs":[{"output_type":"stream","name":"stdout","text":["This is for csv #1\n","start_row: 36\n","end_row: 97\n","This is for csv #2\n","start_row: 32\n","end_row: 55\n","This is for csv #3\n","start_row: 40\n","end_row: 54\n","This is for csv #4\n","start_row: 36\n","end_row: 74\n","This is for csv #5\n","start_row: 32\n","end_row: 156\n","This is for csv #6\n","start_row: 39\n","end_row: 61\n","This is for csv #7\n","start_row: 49\n","end_row: 92\n","This is for csv #8\n","start_row: 37\n","end_row: 175\n","This is for csv #9\n","start_row: 49\n","end_row: 79\n","This is for csv #10\n","start_row: 49\n","end_row: 137\n","This is for csv #11\n","start_row: 33\n","end_row: 219\n","This is for csv #12\n","start_row: 39\n","end_row: 88\n","This is for csv #13\n","start_row: 47\n","end_row: 236\n","This is for csv #14\n","start_row: 25\n","end_row: 65\n","This is for csv #15\n","start_row: 38\n","end_row: 92\n","This is for csv #16\n","start_row: 31\n","end_row: 89\n","This is for csv #17\n","start_row: 39\n","end_row: 119\n","This is for csv #18\n","start_row: 22\n","end_row: 86\n","This is for csv #19\n","start_row: 28\n","end_row: 159\n","This is for csv #20\n","start_row: 39\n","end_row: 157\n","This is for csv #21\n","start_row: 28\n","end_row: 81\n","This is for csv #22\n","start_row: 30\n","end_row: 56\n","This is for csv #23\n","start_row: 24\n","end_row: 52\n","This is for csv #24\n","start_row: 55\n","end_row: 81\n","This is for csv #25\n","start_row: 30\n","end_row: 62\n","This is for csv #26\n","start_row: 39\n","end_row: 77\n","This is for csv #27\n","start_row: 19\n","end_row: 108\n","This is for csv #28\n","start_row: 30\n","end_row: 87\n","This is for csv #29\n","start_row: 34\n","end_row: 55\n","This is for csv #30\n","start_row: 27\n","end_row: 67\n","This is for csv #31\n","start_row: 25\n","end_row: 52\n","This is for csv #32\n","start_row: 24\n","end_row: 44\n","This is for csv #33\n","start_row: 22\n","end_row: 31\n","This is for csv #34\n","start_row: 20\n","end_row: 36\n","This is for csv #35\n","start_row: 25\n","end_row: 48\n","This is for csv #36\n","start_row: 35\n","end_row: 61\n","This is for csv #37\n","start_row: 36\n","end_row: 221\n","extract_metrics_from_directory ran successfully\n","combine_metrics ran successfully\n"]}],"source":["MASTER_VIDEO_DIRECTORY = 'drive/MyDrive/Colab Notebooks/Zebrafish Data/TDP43 G348C Touch Response 02-08-24/WT'\n","videos_to_fish_data(MASTER_VIDEO_DIRECTORY, 0.337408, 30)\n"]},{"cell_type":"code","source":["MASTER_VIDEO_DIRECTORY = 'drive/MyDrive/Colab Notebooks/Zebrafish Data/TDP43 G348C Touch Response 02-08-24/TDP43'\n","videos_to_fish_data(MASTER_VIDEO_DIRECTORY, 0.337408, 30)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pI3R4MDAa5gv","executionInfo":{"status":"ok","timestamp":1723035248527,"user_tz":240,"elapsed":10700,"user":{"displayName":"Adrien Lacroix","userId":"08986805416727083279"}},"outputId":"4802b1f1-6bce-4024-c0c9-942107f632e1"},"id":"pI3R4MDAa5gv","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["combine_metrics ran successfully\n"]}]},{"cell_type":"markdown","source":["Code for deleting various folders at various stages of videos_to_fish_data (for testing purposes)"],"metadata":{"id":"cmyRYRaZsgsq"},"id":"cmyRYRaZsgsq"},{"cell_type":"code","source":["#shutil.rmtree(f'drive/MyDrive/Colab Notebooks/Zebrafish Data/TDP43 G348C Touch Response 02-08-24/WT/predicted_csvs/corrected_csvs')\n","#shutil.rmtree(f'drive/MyDrive/Colab Notebooks/Zebrafish Data/TDP43 G348C Touch Response 02-08-24/WT/predicted_csvs/corrected_csvs/formatted_data')"],"metadata":{"id":"9jlSyafrsPYi"},"id":"9jlSyafrsPYi","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#shutil.rmtree(f'drive/MyDrive/Colab Notebooks/Zebrafish Data/TDP43 G348C Touch Response 02-08-24/WT/predicted_csvs/corrected_csvs')\n","#shutil.rmtree(f'drive/MyDrive/Colab Notebooks/Zebrafish Data/TDP43 G348C Touch Response 02-08-24/WT/predicted_csvs/corrected_csvs/formatted_data')"],"metadata":{"id":"UPrcLiwCsgCh"},"id":"UPrcLiwCsgCh","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"70732b19-1f78-4da9-95f0-82ead09db524","metadata":{"id":"70732b19-1f78-4da9-95f0-82ead09db524"},"outputs":[],"source":["#TODO: Figure out how to package this code up and run it as independent software (i.e. without having to have jupyter notebooks, etc)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}